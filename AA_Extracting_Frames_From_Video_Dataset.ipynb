{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting Frames From Video Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lzPIQy_mq3CQPbkBQ_Nii2MoZYjIJV5s",
      "authorship_tag": "ABX9TyMVM5hLaAq5gXmugpROjuEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajni0829/Computer-Vision-Prac/blob/main/AA_Extracting_Frames_From_Video_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TASK-1"
      ],
      "metadata": {
        "id": "_0b8qMksgofZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Extracting Frames/Segments From Video**"
      ],
      "metadata": {
        "id": "eBhLFCM5gP8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import time\n"
      ],
      "metadata": {
        "id": "PQ8o5y_FZsRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_frame(video_path, save_dir, gap=10):\n",
        "    name = video_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    save_path = os.path.join(save_dir, name)\n",
        "    create_dir(save_path)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    idx = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret == False:\n",
        "            cap.release()\n",
        "            break\n",
        "\n",
        "        if idx == 0:\n",
        "            cv2.imwrite(f\"{save_path}/{idx}.png\", frame)\n",
        "        else:\n",
        "            if idx % gap == 0:\n",
        "                cv2.imwrite(f\"{save_path}/{idx}.png\", frame)\n",
        "\n",
        "        idx += 1"
      ],
      "metadata": {
        "id": "pPRZq-vXgI3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dir(path):\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "    except OSError:\n",
        "        print(f\"ERROR: creating directory with name {path}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_paths = glob(\"/content/drive/MyDrive/Dataset_Vdo/Food_chain.mp4\")\n",
        "    save_dir = \"Extracted_Pics\"\n",
        "\n",
        "    for path in video_paths:\n",
        "      # start = time.time()\n",
        "      save_frame(path, save_dir, gap=5)\n",
        "      # end = time.time()\n"
      ],
      "metadata": {
        "id": "Y6AgQWdiZIYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output: After running the above code, a folder named **Extracted_Pics** is created and snapshots taken from Video at every 5ms is saved."
      ],
      "metadata": {
        "id": "LnzdTfzGjZpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, if we have a video and we need to detect the frame and display the name of the object and classify it, the procedure is as follows --\n"
      ],
      "metadata": {
        "id": "Q7LNlJZ4hcLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LmSR2D9Ahs3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = '/content/drive/MyDrive/API_Config/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
        "frozen_model = '/content/drive/MyDrive/API_Config/frozen_inference_graph.pb'"
      ],
      "metadata": {
        "id": "JGHvjLVwhs6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cv2.dnn_DetectionModel(frozen_model,config_file)\n"
      ],
      "metadata": {
        "id": "cZ-Aj_Rahs9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import *\n",
        "\n",
        "global ftp\n",
        "\n",
        "classLabels = []\n",
        "file_name = '/content/drive/MyDrive/API_Config/labels.txt'\n",
        "\n",
        "with open(file_name,'rt') as fpt:\n",
        "  classLabels = ftp.read().rstrip('\\n').split('\\n')"
      ],
      "metadata": {
        "id": "XdSokyMYhtAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.setInputSize(320,320)\n",
        "model.setInputScale(1.0/127.5)\n",
        "model.setInputSize(127.5, 127.5, 127.5)\n",
        "model.SetInputSwapRB(True)\n"
      ],
      "metadata": {
        "id": "bH7sATsWhtDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading an image\n",
        "img = cv2.imread('/content/drive/MyDrive/IMG20191027204217.jpg')\n"
      ],
      "metadata": {
        "id": "lea8WskBiBkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "d_fVed9RiBqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "JZWDvQ_6iBu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classIndex, confidece, bbox = model.detect(img.confThreshold=0.8)\n",
        "print(classIndex)"
      ],
      "metadata": {
        "id": "9mqlAaDQiBzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font_scale = 3\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "for classInd, conf, boxes in zip(classIndex, confidece.flatten(),bbox):\n",
        "  cv2.rectangle(img,boxes,(255,0,0),2)\n",
        "  cv2.putText(img,classLabels[classInd-1],(boxes[0]+10,boxes[1]+40),font,fontScale=font_scale,color=(0,255,0),thickness=3)\n"
      ],
      "metadata": {
        "id": "FBs3ORubiPP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Video\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Dataset_Vdo/Food_chain.mp4\")\n",
        "\n",
        "# check if video is opened correctly\n",
        "if not cap.isOpened():\n",
        "  cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "  raise IOError(\"Cannot Open The video\")\n",
        "\n",
        "font_scale = 3\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  classIndex,confidece,bbox = model.detect(frame,confThreshold=0.55)\n",
        "  print(classIndex)\n",
        "\n",
        "  if(len(classIndex) != 0):\n",
        "    for classInd, conf, boxes in zip(classIndex.flatten(), confidece.flatten(),bbox):\n",
        "      if (classInd <= 80):\n",
        "        cv2.rectangle(img,boxes,(255,0,0),2)\n",
        "        cv2.putText(frame,classLabels[classInd-1],(boxes[0]+10,boxes[1]+40),font,fontScale=font_scale,color=(0,255,0),thickness=3)\n",
        "\n",
        "  cv2.imshow(\"Object Detection\",frame)\n",
        "\n",
        "  if cv2.waitKey(2) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "7VDb8K4CiPSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}